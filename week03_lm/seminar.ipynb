{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "k1gpzj4guo8e1riwj3om1k"
   },
   "source": [
    "### N-gram language models or how to write scientific papers (4 pts)\n",
    "\n",
    "We shall train our language model on a corpora of [ArXiv](http://arxiv.org/) articles and see if we can generate a new one!\n",
    "\n",
    "![img](https://media.npr.org/assets/img/2013/12/10/istock-18586699-monkey-computer_brick-16e5064d3378a14e0e4c2da08857efe03c04695e-s800-c85.jpg)\n",
    "\n",
    "_data by neelshah18 from [here](https://www.kaggle.com/neelshah18/arxivdataset/)_\n",
    "\n",
    "_Disclaimer: this has nothing to do with actual science. But it's fun, so who cares?!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellId": "u8jdaiy68oib3jvr4k01",
    "execution": {
     "iopub.execute_input": "2024-10-10T13:43:57.490109Z",
     "iopub.status.busy": "2024-10-10T13:43:57.489031Z",
     "iopub.status.idle": "2024-10-10T13:43:57.549554Z",
     "shell.execute_reply": "2024-10-10T13:43:57.548557Z",
     "shell.execute_reply.started": "2024-10-10T13:43:57.490035Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellId": "0c76vnyl3zui9yhtkodgrlf",
    "execution": {
     "iopub.execute_input": "2024-10-10T13:43:57.552317Z",
     "iopub.status.busy": "2024-10-10T13:43:57.551039Z",
     "iopub.status.idle": "2024-10-10T13:43:58.448381Z",
     "shell.execute_reply": "2024-10-10T13:43:58.447506Z",
     "shell.execute_reply.started": "2024-10-10T13:43:57.552262Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>day</th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>month</th>\n",
       "      <th>summary</th>\n",
       "      <th>tag</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12799</th>\n",
       "      <td>[{'name': 'Yair Rivenson'}, {'name': 'Zoltan G...</td>\n",
       "      <td>12</td>\n",
       "      <td>1705.04709v1</td>\n",
       "      <td>[{'rel': 'related', 'href': 'http://dx.doi.org...</td>\n",
       "      <td>5</td>\n",
       "      <td>We demonstrate that a deep neural network can ...</td>\n",
       "      <td>[{'term': 'cs.LG', 'scheme': 'http://arxiv.org...</td>\n",
       "      <td>Deep Learning Microscopy</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17741</th>\n",
       "      <td>[{'name': 'Christian Stab'}, {'name': 'Tristan...</td>\n",
       "      <td>15</td>\n",
       "      <td>1802.05758v1</td>\n",
       "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
       "      <td>2</td>\n",
       "      <td>Argument mining is a core technology for autom...</td>\n",
       "      <td>[{'term': 'cs.CL', 'scheme': 'http://arxiv.org...</td>\n",
       "      <td>Cross-topic Argument Mining from Heterogeneous...</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35841</th>\n",
       "      <td>[{'name': 'Pedro Larrañaga'}, {'name': 'Ramon ...</td>\n",
       "      <td>16</td>\n",
       "      <td>1301.3871v1</td>\n",
       "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
       "      <td>1</td>\n",
       "      <td>This paper shows how the Bayesian network para...</td>\n",
       "      <td>[{'term': 'cs.AI', 'scheme': 'http://arxiv.org...</td>\n",
       "      <td>Combinatorial Optimization by Learning and Sim...</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>[{'name': 'Brian McWilliams'}, {'name': 'David...</td>\n",
       "      <td>24</td>\n",
       "      <td>1306.5554v2</td>\n",
       "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
       "      <td>6</td>\n",
       "      <td>This paper presents Correlated Nystrom Views (...</td>\n",
       "      <td>[{'term': 'stat.ML', 'scheme': 'http://arxiv.o...</td>\n",
       "      <td>Correlated random features for fast semi-super...</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26291</th>\n",
       "      <td>[{'name': 'Michal Balazia'}, {'name': 'Petr So...</td>\n",
       "      <td>22</td>\n",
       "      <td>1609.06936v4</td>\n",
       "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
       "      <td>9</td>\n",
       "      <td>MoCap-based human identification, as a pattern...</td>\n",
       "      <td>[{'term': 'cs.CV', 'scheme': 'http://arxiv.org...</td>\n",
       "      <td>Walker-Independent Features for Gait Recogniti...</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  author  ...  year\n",
       "12799  [{'name': 'Yair Rivenson'}, {'name': 'Zoltan G...  ...  2017\n",
       "17741  [{'name': 'Christian Stab'}, {'name': 'Tristan...  ...  2018\n",
       "35841  [{'name': 'Pedro Larrañaga'}, {'name': 'Ramon ...  ...  2013\n",
       "5390   [{'name': 'Brian McWilliams'}, {'name': 'David...  ...  2013\n",
       "26291  [{'name': 'Michal Balazia'}, {'name': 'Petr So...  ...  2016\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternative manual download link: https://yadi.sk/d/_nGyU2IajjR9-w\n",
    "# !wget \"https://www.dropbox.com/s/99az9n1b57qkd9j/arxivData.json.tar.gz?dl=1\" -O arxivData.json.tar.gz\n",
    "# !tar -xvzf arxivData.json.tar.gz\n",
    "data = pd.read_json(\"./arxivData.json\")\n",
    "data.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellId": "lbyqb5rx7j8jpo591r06ak",
    "execution": {
     "iopub.execute_input": "2024-10-10T13:43:58.450500Z",
     "iopub.status.busy": "2024-10-10T13:43:58.449450Z",
     "iopub.status.idle": "2024-10-10T13:43:58.823931Z",
     "shell.execute_reply": "2024-10-10T13:43:58.822971Z",
     "shell.execute_reply.started": "2024-10-10T13:43:58.450462Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Differential Contrastive Divergence ; This paper has been retracted.',\n",
       " 'What Does Artificial Life Tell Us About Death? ; Short philosophical essay',\n",
       " 'P=NP ; We claim to resolve the P=?NP problem via a formal argument for P=NP.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assemble lines: concatenate title and description\n",
    "lines = data.apply(lambda row: row['title'] + ' ; ' + row['summary'].replace(\"\\n\", ' '), axis=1).tolist()\n",
    "\n",
    "sorted(lines, key=len)[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "7u97m5s8ekl5zd5a43a1yc"
   },
   "source": [
    "### Tokenization\n",
    "\n",
    "You know the dril. The data is messy. Go clean the data. Use WordPunctTokenizer or something.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellId": "u8rvfk719iek97t3rarwr",
    "execution": {
     "iopub.execute_input": "2024-10-10T13:43:58.826657Z",
     "iopub.status.busy": "2024-10-10T13:43:58.825793Z",
     "iopub.status.idle": "2024-10-10T13:44:05.786876Z",
     "shell.execute_reply": "2024-10-10T13:44:05.785582Z",
     "shell.execute_reply.started": "2024-10-10T13:43:58.826605Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task: convert lines (in-place) into strings of space-separated tokens. Import & use WordPunctTokenizer\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tokenizer = WordPunctTokenizer()\n",
    "lines = [' '.join(tokenizer.tokenize(line.lower())) for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellId": "w88nddpp2k8edoeyyyjh0l",
    "execution": {
     "iopub.execute_input": "2024-10-10T13:44:05.788536Z",
     "iopub.status.busy": "2024-10-10T13:44:05.788014Z",
     "iopub.status.idle": "2024-10-10T13:44:05.841364Z",
     "shell.execute_reply": "2024-10-10T13:44:05.840478Z",
     "shell.execute_reply.started": "2024-10-10T13:44:05.788500Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert sorted(lines, key=len)[0] == \\\n",
    "    'differential contrastive divergence ; this paper has been retracted .'\n",
    "assert sorted(lines, key=len)[2] == \\\n",
    "    'p = np ; we claim to resolve the p =? np problem via a formal argument for p = np .'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "qb6h3hxmr095egzv8rlzul"
   },
   "source": [
    "### N-Gram Language Model (1point)\n",
    "\n",
    "A language model is a probabilistic model that estimates text probability: the joint probability of all tokens $w_t$ in text $X$: $P(X) = P(w_1, \\dots, w_T)$.\n",
    "\n",
    "It can do so by following the chain rule:\n",
    "$$P(w_1, \\dots, w_T) = P(w_1)P(w_2 \\mid w_1)\\dots P(w_T \\mid w_1, \\dots, w_{T-1}).$$ \n",
    "\n",
    "The problem with such approach is that the final term $P(w_T \\mid w_1, \\dots, w_{T-1})$ depends on $n-1$ previous words. This probability is impractical to estimate for long texts, e.g. $T = 1000$.\n",
    "\n",
    "One popular approximation is to assume that next word only depends on a finite amount of previous words:\n",
    "\n",
    "$$P(w_t \\mid w_1, \\dots, w_{t - 1}) = P(w_t \\mid w_{t - n + 1}, \\dots, w_{t - 1})$$\n",
    "\n",
    "Such model is called __n-gram language model__ where n is a parameter. For example, in 3-gram language model, each word only depends on 2 previous words. \n",
    "\n",
    "$$\n",
    "    P(w_1, \\dots, w_n) = \\prod_t P(w_t \\mid w_{t - n + 1}, \\dots, w_{t - 1}).\n",
    "$$\n",
    "\n",
    "You can also sometimes see such approximation under the name of _n-th order markov assumption_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "u68wydbiioqlp5gl96mhd"
   },
   "source": [
    "The first stage to building such a model is counting all word occurences given N-1 previous words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellId": "og84gjipnumsakhiiu9ap",
    "execution": {
     "iopub.execute_input": "2024-10-10T13:44:05.843884Z",
     "iopub.status.busy": "2024-10-10T13:44:05.842595Z",
     "iopub.status.idle": "2024-10-10T13:44:06.027186Z",
     "shell.execute_reply": "2024-10-10T13:44:06.026317Z",
     "shell.execute_reply.started": "2024-10-10T13:44:05.843841Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# special tokens: \n",
    "# - `UNK` represents absent tokens, \n",
    "# - `EOS` is a special token after the end of sequence\n",
    "\n",
    "UNK, EOS = \"_UNK_\", \"_EOS_\"\n",
    "\n",
    "def count_ngrams(lines, n):\n",
    "    \"\"\"\n",
    "    Count how many times each word occured after (n - 1) previous words\n",
    "    :param lines: an iterable of strings with space-separated tokens\n",
    "    :returns: a dictionary { tuple(prefix_tokens): {next_token_1: count_1, next_token_2: count_2}}\n",
    "\n",
    "    When building counts, please consider the following two edge cases:\n",
    "    - if prefix is shorter than (n - 1) tokens, it should be padded with UNK. For n=3,\n",
    "      empty prefix: \"\" -> (UNK, UNK)\n",
    "      short prefix: \"the\" -> (UNK, the)\n",
    "      long prefix: \"the new approach\" -> (new, approach)\n",
    "    - you should add a special token, EOS, at the end of each sequence\n",
    "      \"... with deep neural networks .\" -> (..., with, deep, neural, networks, ., EOS)\n",
    "      count the probability of this token just like all others.\n",
    "    \"\"\"\n",
    "    counts = defaultdict(Counter)\n",
    "    # counts[(word1, word2)][word3] = how many times word3 occured after (word1, word2)\n",
    "\n",
    "    for line in lines:\n",
    "        line_list = [UNK] * (n - 1) + line.split(' ') + [EOS]\n",
    "        for end_idx in range(n - 1, len(line_list)):\n",
    "            counts[tuple(line_list[end_idx - n + 1 : end_idx])].update([line_list[end_idx]])\n",
    "    \n",
    "    return counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T13:44:06.028818Z",
     "iopub.status.busy": "2024-10-10T13:44:06.028287Z",
     "iopub.status.idle": "2024-10-10T13:44:06.080316Z",
     "shell.execute_reply": "2024-10-10T13:44:06.079521Z",
     "shell.execute_reply.started": "2024-10-10T13:44:06.028782Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dummy_lines = sorted(lines, key=len)[:100]\n",
    "dummy_counts = count_ngrams(dummy_lines, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellId": "xyf2he6lak9mmqarl3nck",
    "execution": {
     "iopub.execute_input": "2024-10-10T13:44:06.083109Z",
     "iopub.status.busy": "2024-10-10T13:44:06.081295Z",
     "iopub.status.idle": "2024-10-10T13:44:06.126391Z",
     "shell.execute_reply": "2024-10-10T13:44:06.125554Z",
     "shell.execute_reply.started": "2024-10-10T13:44:06.083066Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n"
     ]
    }
   ],
   "source": [
    "# let's test it\n",
    "dummy_lines = sorted(lines, key=len)[:100]\n",
    "dummy_counts = count_ngrams(dummy_lines, n=3)\n",
    "assert set(map(len, dummy_counts.keys())) == {2}, \"please only count {n-1}-grams\"\n",
    "print(len(dummy_counts[('_UNK_', '_UNK_')]))\n",
    "assert len(dummy_counts[('_UNK_', '_UNK_')]) == 78\n",
    "assert dummy_counts['_UNK_', 'a']['note'] == 3\n",
    "assert dummy_counts['p', '=']['np'] == 2\n",
    "assert dummy_counts['author', '.']['_EOS_'] == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "4j620npeqvj0k8ak8xqx8xk"
   },
   "source": [
    "Once we can count N-grams, we can build a probabilistic language model.\n",
    "The simplest way to compute probabilities is in proporiton to counts:\n",
    "\n",
    "$$ P(w_t | prefix) = { Count(prefix, w_t) \\over \\sum_{\\hat w} Count(prefix, \\hat w) } $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellId": "c7cm76wmzlaa12bctznzei",
    "execution": {
     "iopub.execute_input": "2024-10-10T13:44:06.130009Z",
     "iopub.status.busy": "2024-10-10T13:44:06.128696Z",
     "iopub.status.idle": "2024-10-10T13:44:06.161907Z",
     "shell.execute_reply": "2024-10-10T13:44:06.161069Z",
     "shell.execute_reply.started": "2024-10-10T13:44:06.129966Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NGramLanguageModel:    \n",
    "    def __init__(self, lines, n):\n",
    "        \"\"\" \n",
    "        Train a simple count-based language model: \n",
    "        compute probabilities P(w_t | prefix) given ngram counts\n",
    "        \n",
    "        :param n: computes probability of next token given (n - 1) previous words\n",
    "        :param lines: an iterable of strings with space-separated tokens\n",
    "        \"\"\"\n",
    "        assert n >= 1\n",
    "        self.n = n\n",
    "    \n",
    "        counts = count_ngrams(lines, self.n)\n",
    "        \n",
    "        # compute token proabilities given counts\n",
    "        self.probs = defaultdict(Counter)\n",
    "        # probs[(word1, word2)][word3] = P(word3 | word1, word2)\n",
    "        \n",
    "        # populate self.probs with actual probabilities\n",
    "        for prefix in counts:\n",
    "            for word in counts[prefix]:\n",
    "                self.probs[prefix][word] = counts[prefix][word] / counts[prefix].total()\n",
    "            \n",
    "    def get_possible_next_tokens(self, prefix):\n",
    "        \"\"\"\n",
    "        :param prefix: string with space-separated prefix tokens\n",
    "        :returns: a dictionary {token : it's probability} for all tokens with positive probabilities\n",
    "        \"\"\"\n",
    "        prefix = prefix.split()\n",
    "        prefix = prefix[max(0, len(prefix) - self.n + 1):]\n",
    "        prefix = [ UNK ] * (self.n - 1 - len(prefix)) + prefix\n",
    "        return self.probs[tuple(prefix)]\n",
    "    \n",
    "    def get_next_token_prob(self, prefix, next_token):\n",
    "        \"\"\"\n",
    "        :param prefix: string with space-separated prefix tokens\n",
    "        :param next_token: the next token to predict probability for\n",
    "        :returns: P(next_token|prefix) a single number, 0 <= P <= 1\n",
    "        \"\"\"\n",
    "        return self.get_possible_next_tokens(prefix).get(next_token, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "0ftnn4nmuzrup6c0vvhb8q"
   },
   "source": [
    "Let's test it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cellId": "a7zajcnvhqupvcrmacvkur",
    "execution": {
     "iopub.execute_input": "2024-10-10T13:44:06.164235Z",
     "iopub.status.busy": "2024-10-10T13:44:06.163028Z",
     "iopub.status.idle": "2024-10-10T13:44:06.198742Z",
     "shell.execute_reply": "2024-10-10T13:44:06.197849Z",
     "shell.execute_reply.started": "2024-10-10T13:44:06.164195Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dummy_lm = NGramLanguageModel(dummy_lines, n=3)\n",
    "\n",
    "p_initial = dummy_lm.get_possible_next_tokens('') # '' -> ['_UNK_', '_UNK_']\n",
    "assert np.allclose(p_initial['learning'], 0.02)\n",
    "assert np.allclose(p_initial['a'], 0.13)\n",
    "assert np.allclose(p_initial.get('meow', 0), 0)\n",
    "assert np.allclose(sum(p_initial.values()), 1)\n",
    "\n",
    "p_a = dummy_lm.get_possible_next_tokens('a') # '' -> ['_UNK_', 'a']\n",
    "assert np.allclose(p_a['machine'], 0.15384615)\n",
    "assert np.allclose(p_a['note'], 0.23076923)\n",
    "assert np.allclose(p_a.get('the', 0), 0)\n",
    "assert np.allclose(sum(p_a.values()), 1)\n",
    "\n",
    "assert np.allclose(dummy_lm.get_possible_next_tokens('a note')['on'], 1)\n",
    "assert dummy_lm.get_possible_next_tokens('a machine') == \\\n",
    "    dummy_lm.get_possible_next_tokens(\"there have always been ghosts in a machine\"), \\\n",
    "    \"your 3-gram model should only depend on 2 previous words\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "oh8r9a41kuk4r51wra9"
   },
   "source": [
    "Now that you've got a working n-gram language model, let's see what sequences it can generate. But first, let's train it on the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cellId": "f17xoejjppmooo2nopw4xo",
    "execution": {
     "iopub.execute_input": "2024-10-10T13:44:06.200661Z",
     "iopub.status.busy": "2024-10-10T13:44:06.199728Z",
     "iopub.status.idle": "2024-10-10T13:44:30.382592Z",
     "shell.execute_reply": "2024-10-10T13:44:30.381004Z",
     "shell.execute_reply.started": "2024-10-10T13:44:06.200622Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lm = NGramLanguageModel(lines, n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "2kd9glwnkr470qc4bt7f1e"
   },
   "source": [
    "The process of generating sequences is... well, it's sequential. You maintain a list of tokens and iteratively add next token by sampling with probabilities.\n",
    "\n",
    "$ X = [] $\n",
    "\n",
    "__forever:__\n",
    "* $w_{next} \\sim P(w_{next} | X)$\n",
    "* $X = concat(X, w_{next})$\n",
    "\n",
    "\n",
    "Instead of sampling with probabilities, one can also try always taking most likely token, sampling among top-K most likely tokens or sampling with temperature. In the latter case (temperature), one samples from\n",
    "\n",
    "$$w_{next} \\sim {P(w_{next} | X) ^ {1 / \\tau} \\over \\sum_{\\hat w} P(\\hat w | X) ^ {1 / \\tau}}$$\n",
    "\n",
    "Where $\\tau > 0$ is model temperature. If $\\tau << 1$, more likely tokens will be sampled with even higher probability while less likely tokens will vanish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cellId": "sgbatlm9vzb4z889fho7",
    "execution": {
     "iopub.execute_input": "2024-10-10T13:44:30.385714Z",
     "iopub.status.busy": "2024-10-10T13:44:30.384852Z",
     "iopub.status.idle": "2024-10-10T13:44:30.417042Z",
     "shell.execute_reply": "2024-10-10T13:44:30.416160Z",
     "shell.execute_reply.started": "2024-10-10T13:44:30.385673Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_next_token(lm, prefix, temperature=1.0):\n",
    "    \"\"\"\n",
    "    return next token after prefix;\n",
    "    :param temperature: samples proportionally to lm probabilities ^ (1 / temperature)\n",
    "        if temperature == 0, always takes most likely token. Break ties arbitrarily.\n",
    "    \"\"\"\n",
    "    tokens_and_probs = lm.get_possible_next_tokens(prefix)\n",
    "    if temperature == 0:\n",
    "        return tokens_and_probs.most_common(1)[0][0]\n",
    "    tokens_list = list(tokens_and_probs.keys())\n",
    "    new_probs = np.array([tokens_and_probs[token] ** (1 / temperature) for token in tokens_list])\n",
    "    new_probs /= sum(new_probs)\n",
    "    generated_token = np.random.choice(tokens_list, 1, p=new_probs)[0]\n",
    "    return generated_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cellId": "98l40131wjtd5xbdm5b2nr",
    "execution": {
     "iopub.execute_input": "2024-10-10T13:44:30.419152Z",
     "iopub.status.busy": "2024-10-10T13:44:30.418308Z",
     "iopub.status.idle": "2024-10-10T13:44:34.452968Z",
     "shell.execute_reply": "2024-10-10T13:44:34.452130Z",
     "shell.execute_reply.started": "2024-10-10T13:44:30.419098Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looks nice!\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "test_freqs = Counter([get_next_token(lm, 'there have') for _ in range(10000)])\n",
    "assert 250 < test_freqs['not'] < 450\n",
    "assert 8500 < test_freqs['been'] < 9500\n",
    "assert 1 < test_freqs['lately'] < 200\n",
    "\n",
    "test_freqs = Counter([get_next_token(lm, 'deep', temperature=1.0) for _ in range(10000)])\n",
    "assert 1500 < test_freqs['learning'] < 3000\n",
    "test_freqs = Counter([get_next_token(lm, 'deep', temperature=0.5) for _ in range(10000)])\n",
    "assert 8000 < test_freqs['learning'] < 9000\n",
    "test_freqs = Counter([get_next_token(lm, 'deep', temperature=0.0) for _ in range(10000)])\n",
    "assert test_freqs['learning'] == 10000\n",
    "\n",
    "print(\"Looks nice!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "ux4n8iq523n4s3ftrelhxj"
   },
   "source": [
    "Let's have fun with this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cellId": "1nnnycga61rijt6nd8zai",
    "execution": {
     "iopub.execute_input": "2024-10-10T13:44:34.456526Z",
     "iopub.status.busy": "2024-10-10T13:44:34.454070Z",
     "iopub.status.idle": "2024-10-10T13:44:34.522109Z",
     "shell.execute_reply": "2024-10-10T13:44:34.521190Z",
     "shell.execute_reply.started": "2024-10-10T13:44:34.456484Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all you need ; the constraint that curves of reduced error pruning ; the segmentation results with the fusion of camera views in freehand ultrasound ; ultrasound ( ivus ) is the selection policy , and weight vectors play the game - learning with sequence ( in a hidden matrix given limited computational power may enable the derivation of meaning ( or negativity of the higher layers encode the cue - specific distortion type and placement within field , such as camera - equipped machine , another \" accelerator \" of its relation with the presence of latent domains can be done over\n"
     ]
    }
   ],
   "source": [
    "prefix = 'all you need' # <- your ideas :)\n",
    "\n",
    "for i in range(100):\n",
    "    prefix += ' ' + get_next_token(lm, prefix)\n",
    "    if prefix.endswith(EOS) or len(lm.get_possible_next_tokens(prefix)) == 0:\n",
    "        break\n",
    "        \n",
    "print(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cellId": "pxyjsv3b7r8thdfxlgitl",
    "execution": {
     "iopub.execute_input": "2024-10-10T13:44:34.525064Z",
     "iopub.status.busy": "2024-10-10T13:44:34.523211Z",
     "iopub.status.idle": "2024-10-10T13:44:34.579288Z",
     "shell.execute_reply": "2024-10-10T13:44:34.578424Z",
     "shell.execute_reply.started": "2024-10-10T13:44:34.525022Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diffusion model ( hmm ) and least squares , and the energy function , which are the most popular image classification . the proposed approach can be used to train a deep learning approach for the purposes of training data , and is superior to the problem of finding a set of points in the context of the proposed method . _EOS_\n"
     ]
    }
   ],
   "source": [
    "prefix = 'diffusion model' # <- more of your ideas\n",
    "\n",
    "for i in range(100):\n",
    "    prefix += ' ' + get_next_token(lm, prefix, temperature=0.5)\n",
    "    if prefix.endswith(EOS) or len(lm.get_possible_next_tokens(prefix)) == 0:\n",
    "        break\n",
    "        \n",
    "print(prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "balABOBA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "2n90bscmzfko0qnctp7ysc"
   },
   "source": [
    "__More in the homework:__ nucleus sampling, top-k sampling, beam search(not for the faint of heart)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "3gdmey7g8at5n5c5x4gayh"
   },
   "source": [
    "### Evaluating language models: perplexity (1point)\n",
    "\n",
    "Perplexity is a measure of how well your model approximates the true probability distribution behind the data. __Smaller perplexity = better model__.\n",
    "\n",
    "To compute perplexity on one sentence, use:\n",
    "$$\n",
    "    {\\mathbb{P}}(w_1 \\dots w_N) = P(w_1, \\dots, w_N)^{-\\frac1N} = \\left( \\prod_t P(w_t \\mid w_{t - n}, \\dots, w_{t - 1})\\right)^{-\\frac1N},\n",
    "$$\n",
    "\n",
    "\n",
    "On the corpora level, perplexity is a product of probabilities of all tokens in all sentences to the power of $1/N$, where $N$ is __total length (in tokens) of all sentences__ in corpora.\n",
    "\n",
    "This number can quickly get too small for float32/float64 precision, so we recommend you to first compute log-perplexity (from log-probabilities) and then take the exponent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cellId": "5hp010xyzzb4vqewo1bhny",
    "execution": {
     "iopub.execute_input": "2024-10-10T13:44:34.581473Z",
     "iopub.status.busy": "2024-10-10T13:44:34.580395Z",
     "iopub.status.idle": "2024-10-10T13:44:34.596283Z",
     "shell.execute_reply": "2024-10-10T13:44:34.595374Z",
     "shell.execute_reply.started": "2024-10-10T13:44:34.581434Z"
    }
   },
   "outputs": [],
   "source": [
    "def perplexity(lm, lines, min_logprob=np.log(10 ** -50.)):\n",
    "    \"\"\"\n",
    "    :param lines: a list of strings with space-separated tokens\n",
    "    :param min_logprob: if log(P(w | ...)) is smaller than min_logprop, set it equal to min_logrob\n",
    "    :returns: corpora-level perplexity - a single scalar number from the formula above\n",
    "    \n",
    "    Note: do not forget to compute P(w_first | empty) and P(eos | full_sequence)\n",
    "    \n",
    "    PLEASE USE lm.get_next_token_prob and NOT lm.get_possible_next_tokens\n",
    "    \"\"\"\n",
    "    summar_len = 0\n",
    "    summ_log_probs = 0\n",
    "    for line in tqdm(lines):\n",
    "        prefix = \"\"\n",
    "        line_list = line.split() + [EOS]\n",
    "        for idx in range(len(line_list)):\n",
    "            summ_log_probs += max(min_logprob, np.log(lm.get_next_token_prob(prefix, line_list[idx])))\n",
    "            prefix = ' '.join([prefix, line_list[idx]])\n",
    "            summar_len += 1\n",
    "\n",
    "    \n",
    "    return np.exp(-1 * summ_log_probs / summar_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cellId": "8b689bobhkey04x7pabupj",
    "execution": {
     "iopub.execute_input": "2024-10-10T13:44:34.600290Z",
     "iopub.status.busy": "2024-10-10T13:44:34.597299Z",
     "iopub.status.idle": "2024-10-10T13:44:35.060259Z",
     "shell.execute_reply": "2024-10-10T13:44:35.059325Z",
     "shell.execute_reply.started": "2024-10-10T13:44:34.600232Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 11751.38it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 10572.99it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 9410.39it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]/tmp/ipykernel_3549/2147869241.py:17: RuntimeWarning: divide by zero encountered in log\n",
      "  summ_log_probs += max(min_logprob, np.log(lm.get_next_token_prob(prefix, line_list[idx])))\n",
      "100%|██████████| 1/1 [00:00<00:00, 2269.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexities: ppx1=318.213 ppx3=1.520 ppx10=1.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lm1 = NGramLanguageModel(dummy_lines, n=1)\n",
    "lm3 = NGramLanguageModel(dummy_lines, n=3)\n",
    "lm10 = NGramLanguageModel(dummy_lines, n=10)\n",
    "\n",
    "ppx1 = perplexity(lm1, dummy_lines)\n",
    "ppx3 = perplexity(lm3, dummy_lines)\n",
    "ppx10 = perplexity(lm10, dummy_lines)\n",
    "ppx_missing = perplexity(lm3, ['the jabberwock , with eyes of flame , '])  # thanks, L. Carrol\n",
    "\n",
    "print(\"Perplexities: ppx1=%.3f ppx3=%.3f ppx10=%.3f\" % (ppx1, ppx3, ppx10))\n",
    "\n",
    "assert all(0 < ppx < 500 for ppx in (ppx1, ppx3, ppx10)), \"perplexity should be non-negative and reasonably small\"\n",
    "assert ppx1 > ppx3 > ppx10, \"higher N models should overfit and \"\n",
    "assert np.isfinite(ppx_missing) and ppx_missing > 10 ** 6, \"missing words should have large but finite perplexity. \" \\\n",
    "    \" Make sure you use min_logprob right\"\n",
    "assert np.allclose([ppx1, ppx3, ppx10], (318.2132342216302, 1.5199996213739575, 1.1838145037901249))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "ypc4lks4vs1li908fqi8"
   },
   "source": [
    "Now let's measure the actual perplexity: we'll split the data into train and test and score model on test data only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cellId": "tjnehsem2lmijkg2lto4w",
    "execution": {
     "iopub.execute_input": "2024-10-10T13:44:47.626484Z",
     "iopub.status.busy": "2024-10-10T13:44:47.624760Z",
     "iopub.status.idle": "2024-10-10T13:46:27.141367Z",
     "shell.execute_reply": "2024-10-10T13:46:27.140457Z",
     "shell.execute_reply.started": "2024-10-10T13:44:47.626436Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10250 [00:00<?, ?it/s]/tmp/ipykernel_3549/2147869241.py:17: RuntimeWarning: divide by zero encountered in log\n",
      "  summ_log_probs += max(min_logprob, np.log(lm.get_next_token_prob(prefix, line_list[idx])))\n",
      "100%|██████████| 10250/10250 [00:10<00:00, 957.24it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 1, Perplexity = 1832.23136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10250/10250 [00:12<00:00, 809.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 2, Perplexity = 85653987.28774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 10250/10250 [00:15<00:00, 681.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 3, Perplexity = 61999196259043346743296.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_lines, test_lines = train_test_split(lines, test_size=0.25, random_state=42)\n",
    "\n",
    "for n in (1, 2, 3):\n",
    "    lm = NGramLanguageModel(n=n, lines=train_lines)\n",
    "    ppx = perplexity(lm, test_lines)\n",
    "    print(\"N = %i, Perplexity = %.5f\" % (n, ppx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "38nfbfkpzgfxik8kccyt1l"
   },
   "outputs": [],
   "source": [
    "# whoops, it just blew up :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "oopn2o57wxm9vbxzycytce"
   },
   "source": [
    "### LM Smoothing\n",
    "\n",
    "The problem with our simple language model is that whenever it encounters an n-gram it has never seen before, it assigns it with the probabilitiy of 0. Every time this happens, perplexity explodes.\n",
    "\n",
    "To battle this issue, there's a technique called __smoothing__. The core idea is to modify counts in a way that prevents probabilities from getting too low. The simplest algorithm here is Additive smoothing (aka [Lapace smoothing](https://en.wikipedia.org/wiki/Additive_smoothing)):\n",
    "\n",
    "$$ P(w_t | prefix) = { Count(prefix, w_t) + \\delta \\over \\sum_{\\hat w} (Count(prefix, \\hat w) + \\delta) } $$\n",
    "\n",
    "If counts for a given prefix are low, additive smoothing will adjust probabilities to a more uniform distribution. Not that the summation in the denominator goes over _all words in the vocabulary_.\n",
    "\n",
    "Here's an example code we've implemented for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cellId": "ioh26rlov6g8l2ssj1c8pm"
   },
   "outputs": [],
   "source": [
    "class LaplaceLanguageModel(NGramLanguageModel): \n",
    "    \"\"\" this code is an example, no need to change anything \"\"\"\n",
    "    def __init__(self, lines, n, delta=1.0):\n",
    "        self.n = n\n",
    "        counts = count_ngrams(lines, self.n)\n",
    "        self.vocab = set(token for token_counts in counts.values() for token in token_counts)\n",
    "        self.probs = defaultdict(Counter)\n",
    "\n",
    "        for prefix in counts:\n",
    "            token_counts = counts[prefix]\n",
    "            total_count = sum(token_counts.values()) + delta * len(self.vocab)\n",
    "            self.probs[prefix] = {token: (token_counts[token] + delta) / total_count\n",
    "                                          for token in token_counts}\n",
    "    def get_possible_next_tokens(self, prefix):\n",
    "        token_probs = super().get_possible_next_tokens(prefix)\n",
    "        missing_prob_total = 1.0 - sum(token_probs.values())\n",
    "        missing_prob = missing_prob_total / max(1, len(self.vocab) - len(token_probs))\n",
    "        return {token: token_probs.get(token, missing_prob) for token in self.vocab}\n",
    "    \n",
    "    def get_next_token_prob(self, prefix, next_token):\n",
    "        token_probs = super().get_possible_next_tokens(prefix)\n",
    "        if next_token in token_probs:\n",
    "            return token_probs[next_token]\n",
    "        else:\n",
    "            missing_prob_total = 1.0 - sum(token_probs.values())\n",
    "            missing_prob_total = max(0, missing_prob_total) # prevent rounding errors\n",
    "            return missing_prob_total / max(1, len(self.vocab) - len(token_probs))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "90vsann3920ie05r2blbmi",
    "execution_id": "3868303d-0bb9-42c6-a9a8-dcf485c8220c"
   },
   "source": [
    "**Disclaimer**: the implementation above assumes all words unknown within a given context to be equally likely, *as well as the words outside of vocabulary*. Therefore, its' perplexity will be lower than it should when encountering such words. Therefore, comparing it with a model with fewer unknown words will not be fair. When implementing your own smoothing, you may handle this by adding a virtual `UNK` token of non-zero probability. Technically, this will result in a model where probabilities do not add up to $1$, but it is close enough for a practice excercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cellId": "3xvxkdxcmfqucruyt66mdc"
   },
   "outputs": [],
   "source": [
    "#test that it's a valid probability model\n",
    "for n in (1, 2, 3):\n",
    "    dummy_lm = LaplaceLanguageModel(dummy_lines, n=n)\n",
    "    assert np.allclose(sum([dummy_lm.get_next_token_prob('a', w_i) for w_i in dummy_lm.vocab]), 1), \"I told you not to break anything! :)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cellId": "j6zqa50koitjjri9ipd8ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 1, Perplexity = 977.67559\n",
      "N = 2, Perplexity = 470.48021\n",
      "N = 3, Perplexity = 3679.44765\n"
     ]
    }
   ],
   "source": [
    "for n in (1, 2, 3):\n",
    "    lm = LaplaceLanguageModel(train_lines, n=n, delta=0.1)\n",
    "    ppx = perplexity(lm, test_lines)\n",
    "    print(\"N = %i, Perplexity = %.5f\" % (n, ppx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "pjuqt30jcerwbz1ym9zv1"
   },
   "outputs": [],
   "source": [
    "# optional: try to sample tokens from such a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "3b8s1y9uls4fosu3yp28gg"
   },
   "source": [
    "### Kneser-Ney smoothing (2 points)\n",
    "\n",
    "Additive smoothing is simple, reasonably good but definitely not a State of The Art algorithm.\n",
    "\n",
    "\n",
    "Your final task in this notebook is to implement [Kneser-Ney](https://en.wikipedia.org/wiki/Kneser%E2%80%93Ney_smoothing) smoothing.\n",
    "\n",
    "It can be computed recurrently, for n>1:\n",
    "\n",
    "$$P_{kn}(w_t | prefix_{n-1}) = { \\max(0, Count(prefix_{n-1}, w_t) - \\delta) \\over \\sum_{\\hat w} Count(prefix_{n-1}, \\hat w)} + \\lambda_{prefix_{n-1}} \\cdot P_{kn}(w_t | prefix_{n-2})$$\n",
    "\n",
    "where\n",
    "- $prefix_{n-1}$ is a tuple of {n-1} previous tokens\n",
    "- $lambda_{prefix_{n-1}}$ is a normalization constant chosen so that probabilities add up to 1\n",
    "- Unigram $P_{kn}(w_t | prefix_{n-2})$ corresponds to Kneser Ney smoothing for {N-1}-gram language model.\n",
    "- Unigram $P_{kn}(w_t)$ is a special case: how likely it is to see x_t in an unfamiliar context\n",
    "\n",
    "See lecture slides or wiki for more detailed formulae.\n",
    "\n",
    "__Your task__ is to\n",
    "- implement `KneserNeyLanguageModel` class,\n",
    "- test it on 1-3 gram language models\n",
    "- find optimal (within reason) smoothing delta for 3-gram language model with Kneser-Ney smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T14:35:21.546966Z",
     "iopub.status.busy": "2024-10-10T14:35:21.545946Z",
     "iopub.status.idle": "2024-10-10T14:35:21.560813Z",
     "shell.execute_reply": "2024-10-10T14:35:21.559997Z",
     "shell.execute_reply.started": "2024-10-10T14:35:21.546920Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kneser_ney_initial(lines, n, vocab):\n",
    "    reverse_counts = defaultdict(Counter)\n",
    "        # reverse_counts[word1][word2] = how many times word2 occured BEFORE word1 \n",
    "\n",
    "    for line in lines:\n",
    "        line_list = [UNK] * (n - 1) + line.split(' ') + [EOS]\n",
    "        for end_idx in range(1, len(line_list)):\n",
    "            reverse_counts[line_list[end_idx]].update([line_list[end_idx - 1]])\n",
    "\n",
    "    total_sum = 0\n",
    "    for cnt in reverse_counts.values():\n",
    "        total_sum += len(cnt)\n",
    "\n",
    "    kneser_probs = {word: len(reverse_counts.get(word, {})) / total_sum for word in vocab}\n",
    "    return kneser_probs\n",
    "\n",
    "def kneser_ney(token, prefix, lines, n, delta, vocab, kneser_initial_probs, already_counted):\n",
    "    if n == 1:\n",
    "        return kneser_initial_probs.get(token, 0)\n",
    "    \n",
    "    else:\n",
    "        first_part, norm_const = None, None\n",
    "        if prefix in already_counted:\n",
    "            cnt = already_counted[prefix]\n",
    "            first_part = max(cnt.get(token, 0) - delta, 0) / cnt.total()\n",
    "            norm_const = delta * len(cnt) / cnt.total() #1 - sum([max(cnt.get(tkn, 0) - delta, 0) for tkn in cnt]) / cnt.total()\n",
    "        else:\n",
    "            first_part = 0\n",
    "            norm_const = 1\n",
    "\n",
    "        ans = first_part + norm_const * kneser_ney(token, prefix[1:], lines, n - 1, delta, vocab, kneser_initial_probs, already_counted)\n",
    "        return ans\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "cellId": "2ix7kzw02v30oye55322all",
    "execution": {
     "iopub.execute_input": "2024-10-10T14:44:08.174858Z",
     "iopub.status.busy": "2024-10-10T14:44:08.173796Z",
     "iopub.status.idle": "2024-10-10T14:44:08.190463Z",
     "shell.execute_reply": "2024-10-10T14:44:08.189670Z",
     "shell.execute_reply.started": "2024-10-10T14:44:08.174811Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class KneserNeyLanguageModel(NGramLanguageModel): \n",
    "    \"\"\" A template for Kneser-Ney language model. Default delta may be suboptimal. \"\"\"\n",
    "    def __init__(self, lines, n, delta=1.0):\n",
    "        self.ngrams = count_ngrams(lines, n)\n",
    "        self.n = n\n",
    "        self.delta = delta\n",
    "        self.lines = lines\n",
    "        self.vocab = set(token for token_counts in self.ngrams.values() for token in token_counts)\n",
    "        \n",
    "        for k in range(2, n, 1):\n",
    "            self.ngrams.update(count_ngrams(lines, k))\n",
    "        self.init_prob = kneser_ney_initial(lines, n, self.vocab)\n",
    "\n",
    "    def get_possible_next_tokens(self, prefix):\n",
    "        return self.kneser_probs[prefix]\n",
    "        \n",
    "    def get_next_token_prob(self, prefix, next_token):\n",
    "        prefix = prefix.split()\n",
    "        prefix = prefix[max(0, len(prefix) - self.n + 1):]\n",
    "        prefix = [ UNK ] * (self.n - 1 - len(prefix)) + prefix\n",
    "        if self.n == 1:\n",
    "            return self.init_prob.get(next_token, 0)\n",
    "        # return self.kneser_probs.get(tuple(prefix), {}).get(next_token, 0)\n",
    "        return kneser_ney(next_token, tuple(prefix), self.lines, self.n, self.delta, self.vocab, self.init_prob, self.ngrams)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "cellId": "lsk91832qbmdt7x1q0a8z4",
    "execution": {
     "iopub.execute_input": "2024-10-10T14:41:47.086153Z",
     "iopub.status.busy": "2024-10-10T14:41:47.085058Z",
     "iopub.status.idle": "2024-10-10T14:41:47.171888Z",
     "shell.execute_reply": "2024-10-10T14:41:47.170603Z",
     "shell.execute_reply.started": "2024-10-10T14:41:47.086108Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting ngrams\n",
      "Counted ngrams -- done\n",
      "Counting initial\n",
      "Counted initial -- done\n",
      "1.0000000000000075\n",
      "Counting ngrams\n",
      "Counted ngrams -- done\n",
      "Counting initial\n",
      "Counted initial -- done\n",
      "0.9999999999999908\n",
      "Counting ngrams\n",
      "Counted ngrams -- done\n",
      "Counting initial\n",
      "Counted initial -- done\n",
      "0.9997191091390208\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "I told you not to break anything! :)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3549/2791719392.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdummy_lm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKneserNeyLanguageModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdummy_lm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_token_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_i\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdummy_lm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdummy_lm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_token_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_i\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdummy_lm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"I told you not to break anything! :)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: I told you not to break anything! :)"
     ]
    }
   ],
   "source": [
    "#test that it's a valid probability model\n",
    "for n in (1, 2, 3):\n",
    "    dummy_lm = KneserNeyLanguageModel(dummy_lines, n=n)\n",
    "    print(sum([dummy_lm.get_next_token_prob('a', w_i) for w_i in dummy_lm.vocab]))\n",
    "    assert np.allclose(sum([dummy_lm.get_next_token_prob('a', w_i) for w_i in dummy_lm.vocab]), 1), \"I told you not to break anything! :)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "cellId": "pp3jtkk9annp1qkou58x1b",
    "execution": {
     "iopub.execute_input": "2024-10-10T14:35:37.075777Z",
     "iopub.status.busy": "2024-10-10T14:35:37.074624Z",
     "iopub.status.idle": "2024-10-10T14:40:10.242902Z",
     "shell.execute_reply": "2024-10-10T14:40:10.241754Z",
     "shell.execute_reply.started": "2024-10-10T14:35:37.075733Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting ngrams\n",
      "Counted ngrams -- done\n",
      "Counting initial\n",
      "Counted initial -- done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10250 [00:00<?, ?it/s]/tmp/ipykernel_3549/2147869241.py:17: RuntimeWarning: divide by zero encountered in log\n",
      "  summ_log_probs += max(min_logprob, np.log(lm.get_next_token_prob(prefix, line_list[idx])))\n",
      "100%|██████████| 10250/10250 [00:10<00:00, 976.28it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 1, Perplexity = 2882.02405\n",
      "Counting ngrams\n",
      "Counted ngrams -- done\n",
      "Counting initial\n",
      "Counted initial -- done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10250/10250 [01:35<00:00, 107.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 2, Perplexity = 404.35703\n",
      "Counting ngrams\n",
      "Counted ngrams -- done\n",
      "Counting initial\n",
      "Counted initial -- done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10250/10250 [01:55<00:00, 88.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 3, Perplexity = 311.53732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for n in (1, 2, 3):\n",
    "    lm = KneserNeyLanguageModel(train_lines, n=n, delta=1.0)\n",
    "    ppx = perplexity(lm, test_lines)\n",
    "    print(\"N = %i, Perplexity = %.5f\" % (n, ppx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T14:45:06.033126Z",
     "iopub.status.busy": "2024-10-10T14:45:06.032312Z",
     "iopub.status.idle": "2024-10-10T15:08:59.148303Z",
     "shell.execute_reply": "2024-10-10T15:08:59.147385Z",
     "shell.execute_reply.started": "2024-10-10T14:45:06.033085Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10250 [00:00<?, ?it/s]/tmp/ipykernel_3549/2147869241.py:17: RuntimeWarning: divide by zero encountered in log\n",
      "  summ_log_probs += max(min_logprob, np.log(lm.get_next_token_prob(prefix, line_list[idx])))\n",
      "100%|██████████| 10250/10250 [01:55<00:00, 88.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta = 0.100, Perplexity = 615.29635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10250/10250 [01:57<00:00, 86.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta = 0.200, Perplexity = 463.12898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10250/10250 [01:57<00:00, 87.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta = 0.300, Perplexity = 394.26297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10250/10250 [01:54<00:00, 89.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta = 0.400, Perplexity = 353.42624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10250/10250 [01:59<00:00, 85.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta = 0.500, Perplexity = 326.33934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 10250/10250 [01:59<00:00, 86.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta = 0.600, Perplexity = 307.51445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 10250/10250 [01:56<00:00, 87.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta = 0.700, Perplexity = 294.52717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10250/10250 [01:59<00:00, 86.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta = 0.800, Perplexity = 286.54726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10250/10250 [01:55<00:00, 88.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta = 0.900, Perplexity = 284.59295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10250/10250 [01:53<00:00, 90.05it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta = 1.000, Perplexity = 311.53732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "perp = []\n",
    "for delta in np.linspace(0.1, 1.0, 10):\n",
    "    lm = KneserNeyLanguageModel(train_lines, n=3, delta=delta)\n",
    "    ppx = perplexity(lm, test_lines)\n",
    "    print(\"delta = %.3f, Perplexity = %.5f\" % (delta, ppx))\n",
    "    perp.append(ppx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T15:10:25.379801Z",
     "iopub.status.busy": "2024-10-10T15:10:25.378686Z",
     "iopub.status.idle": "2024-10-10T15:10:25.573491Z",
     "shell.execute_reply": "2024-10-10T15:10:25.572360Z",
     "shell.execute_reply.started": "2024-10-10T15:10:25.379753Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.linspace(0.1, 1.0, 10), perp, 'bo--')\n",
    "plt.grid()\n",
    "plt.title('Perplexity / delta dependency (N = 3)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "notebookId": "53997d2d-afb8-4477-8874-b6d46299f06c",
  "notebookPath": "seminar.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
